# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Kn504yMHGxvdTebCwjDp44Hxsyg8wuVj
"""

# ============================================
# ML PIPELINE FINAL + VISUALIZATION: SEEDLING DATA (NUMERIC ONLY FOR CORRELATION)
# ============================================

import pandas as pd
import numpy as np
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

print("====================================")
print("ML PIPELINE START")
print("====================================")

# ---------------- STEP 1: LOAD CSV ----------------
column_names = [
    "date", "time", "sensor_status", "temperature", "humidity",
    "motor_pump", "led", "soil_moisture", "height", "growth_stage"
]

data = pd.read_csv("Smart Farming Automation.csv", header=0, names=column_names, encoding="latin1")
print("Columns loaded:", data.columns.tolist())

# ---------------- STEP 2: CLEAN COLUMN NAMES ----------------
data.columns = data.columns.str.strip().str.lower().str.replace(' ', '_').str.replace(r'[^\w]', '', regex=True)
print("Cleaned columns:", data.columns.tolist())

# ---------------- STEP 3: FIX DECIMAL FORMAT ----------------
data = data.replace(',', '.', regex=True)

numeric_cols = ["temperature", "humidity", "soil_moisture", "height"]
for col in numeric_cols:
    data[col] = pd.to_numeric(data[col], errors="coerce")

# ---------------- STEP 4: DROP IRRELEVANT COLUMNS ----------------
data = data.drop(columns=["date", "time", "sensor_status"], errors="ignore")
print("Remaining columns:", data.columns.tolist())

# ---------------- STEP 5: REMOVE LABELS WITH <2 SAMPLES ----------------
counts = data['growth_stage'].value_counts()
valid_labels = counts[counts > 1].index
data = data[data['growth_stage'].isin(valid_labels)]
print("Remaining growth_stage classes:", data['growth_stage'].unique())

# ---------------- STEP 6: FEATURE & LABEL SELECTION ----------------
X = data.drop(columns=["growth_stage"])
Y = data["growth_stage"]

# ---------------- STEP 7: HANDLE MISSING VALUES ----------------
numeric_features = X.select_dtypes(include=[np.number]).columns.tolist()
categorical_features = X.select_dtypes(exclude=[np.number]).columns.tolist()

imputer = SimpleImputer(strategy="mean")
X[numeric_features] = imputer.fit_transform(X[numeric_features])

# ---------------- STEP 8: ENCODING ----------------
X = pd.get_dummies(X, columns=categorical_features, drop_first=True)
label_encoder = LabelEncoder()
Y = label_encoder.fit_transform(Y)
print("Label classes:", label_encoder.classes_)

# ---------------- STEP 9: TRAIN-TEST SPLIT ----------------
stratify_param = Y if data['growth_stage'].nunique() > 1 else None
X_train, X_test, Y_train, Y_test = train_test_split(
    X, Y, test_size=0.2, random_state=42, stratify=stratify_param
)

# ---------------- STEP 10: FEATURE SCALING ----------------
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# ---------------- STEP 11: MODEL TRAINING ----------------
model = SVC(kernel="rbf", C=1.0, gamma="scale")
model.fit(X_train, Y_train)

# ---------------- STEP 12: MODEL EVALUATION ----------------
Y_pred = model.predict(X_test)
print("\nAccuracy:", accuracy_score(Y_test, Y_pred))
print("\nClassification Report:")
print(classification_report(Y_test, Y_pred, target_names=label_encoder.classes_))
cm = confusion_matrix(Y_test, Y_pred)
print("\nConfusion Matrix:\n", cm)

# ---------------- STEP 13: SAMPLE PREDICTION ----------------
sample = X_test[0].reshape(1, -1)
prediction = model.predict(sample)
print("\nSample Predicted Growth Stage:", label_encoder.inverse_transform(prediction))

# =====================================
# VISUALIZATION
# =====================================

# 1️⃣ Confusion Matrix
plt.figure(figsize=(6,4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=label_encoder.classes_,
            yticklabels=label_encoder.classes_)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

# 2️⃣ Feature Correlation (numeric only)
numeric_data = data.select_dtypes(include=[np.number])
correlations = numeric_data.corr()['height'].drop('height').sort_values(ascending=False)

plt.figure(figsize=(8,4))
sns.barplot(x=correlations.values, y=correlations.index)
plt.title('Numeric Feature Correlation with Height')
plt.show()

# 3️⃣ Trend Height vs Growth Stage
plt.figure(figsize=(10,5))
sns.lineplot(x=data.index, y=data['height'], hue=data['growth_stage'], marker='o')
plt.xlabel('Sample Index')
plt.ylabel('Height (cm)')
plt.title('Growth Stage vs Height Over Samples')
plt.show()

# 4️⃣ Sensor Distribution by Growth Stage
plt.figure(figsize=(8,5))
sns.boxplot(x='growth_stage', y='soil_moisture', data=data)
plt.title('Soil Moisture Distribution by Growth Stage')
plt.show()

print("\n====================================")
print("ML PIPELINE + VISUALIZATION COMPLETED SUCCESSFULLY")
print("====================================")